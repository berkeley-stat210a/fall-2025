<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Hypothesis Testing and the Neyman-Pearson Lemma</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-7b1b06e26e1e2798ccde3208f86b5bbd.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-B8G2041HSB"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-B8G2041HSB', { 'anonymize_ip': true});
</script>
<script async="" src="https://siteimproveanalytics.com/js/siteanalyze_6294756.js"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../assets/styles.css">
</head>

<body class="quarto-light">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#hypothesis-testing" id="toc-hypothesis-testing" class="nav-link active" data-scroll-target="#hypothesis-testing"><span class="header-section-number">1</span> Hypothesis Testing</a></li>
  <li><a href="#the-critical-function" id="toc-the-critical-function" class="nav-link" data-scroll-target="#the-critical-function"><span class="header-section-number">2</span> The critical function</a>
  <ul class="collapse">
  <li><a href="#significance-level-and-power" id="toc-significance-level-and-power" class="nav-link" data-scroll-target="#significance-level-and-power"><span class="header-section-number">2.1</span> Significance level and power</a></li>
  <li><a href="#example-the-z-test" id="toc-example-the-z-test" class="nav-link" data-scroll-target="#example-the-z-test"><span class="header-section-number">2.2</span> Example: the <span class="math inline">\(Z\)</span>-test</a></li>
  </ul></li>
  <li><a href="#optimal-testing" id="toc-optimal-testing" class="nav-link" data-scroll-target="#optimal-testing"><span class="header-section-number">3</span> Optimal testing</a>
  <ul class="collapse">
  <li><a href="#likelihood-ratio-test" id="toc-likelihood-ratio-test" class="nav-link" data-scroll-target="#likelihood-ratio-test"><span class="header-section-number">3.1</span> Likelihood Ratio Test</a></li>
  <li><a href="#example-binomial" id="toc-example-binomial" class="nav-link" data-scroll-target="#example-binomial"><span class="header-section-number">3.2</span> Example: Binomial</a></li>
  <li><a href="#uniformly-most-powerful-tests" id="toc-uniformly-most-powerful-tests" class="nav-link" data-scroll-target="#uniformly-most-powerful-tests"><span class="header-section-number">3.3</span> Uniformly most powerful tests</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Hypothesis Testing and the Neyman-Pearson Lemma</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><span class="math display">\[
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\td}{\,\textrm{d}}
\newcommand{\simiid}{\stackrel{\textrm{i.i.d.}}{\sim}}
\newcommand{\simind}{\stackrel{\textrm{ind.}}{\sim}}
\newcommand{\eqas}{\stackrel{\textrm{a.s.}}{=}}
\newcommand{\eqPas}{\stackrel{\cP\textrm{-a.s.}}{=}}
\newcommand{\eqmuas}{\stackrel{\mu\textrm{-a.s.}}{=}}
\newcommand{\eqD}{\stackrel{D}{=}}
\newcommand{\indep}{\perp\!\!\!\!\perp}
\DeclareMathOperator*{\minz}{minimize\;}
\DeclareMathOperator*{\maxz}{minimize\;}
\DeclareMathOperator*{\argmin}{argmin\;}
\DeclareMathOperator*{\argmax}{argmax\;}
\newcommand{\Var}{\textnormal{Var}}
\newcommand{\Cov}{\textnormal{Cov}}
\newcommand{\Corr}{\textnormal{Corr}}
\]</span></p>
<section id="hypothesis-testing" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="hypothesis-testing"><span class="header-section-number">1</span> Hypothesis Testing</h2>
<p>Assume we have a larger model <span class="math inline">\(\cP = \{P_\theta: \theta \in \Theta\}\)</span> (which, as usual, may be “nonparametric” if <span class="math inline">\(\theta\)</span> is an infinite-dimensional object like a density), and two competing hypotheses about where <span class="math inline">\(\theta\)</span> lies:</p>
<ul>
<li><p>Null hypothesis: <span class="math inline">\(H_0: \theta \in \Theta_0\)</span></p></li>
<li><p>Alternative hypothesis: <span class="math inline">\(H_1: \theta \in \Theta_1\)</span></p></li>
</ul>
<p>These hypotheses should be <em>disjoint</em>, meaning <span class="math inline">\(\Theta_0 \cap \Theta_1 = \emptyset\)</span>, and <em>exhaustive</em>, meaning <span class="math inline">\(\Theta_0 \cup \Theta_1 = \Theta\)</span>. Sometimes <span class="math inline">\(\Theta_0\)</span> is specified and <span class="math inline">\(\Theta_1\)</span> is left unspecified; in that case you can assume <span class="math inline">\(\Theta_1 = \Theta \setminus \Theta_0\)</span>.</p>
<p>A few examples to have in mind:</p>
<p><strong>Example 1 (Gaussian summary statistic, a.k.a. <span class="math inline">\(Z\)</span>-test):</strong> We observe <span class="math inline">\(Z \sim N(\theta,1)\)</span> (which is commonly a summary statistic <span class="math inline">\(Z(X)\)</span> from a large data set) and we want to draw an inference about <span class="math inline">\(\theta\)</span>. Two common hypothesis testing settings are the <em>one-sided</em> hypotheses <span class="math inline">\(H_0:\; \theta \leq \theta_0\)</span> vs <span class="math inline">\(H_1:\; \theta &gt; \theta_0\)</span> and the <em>two-sided</em> hypotheses <span class="math inline">\(H_0:\; \theta = \theta_0\)</span> vs <span class="math inline">\(H_1:\; \theta \neq \theta_0\)</span>.</p>
<p><strong>Example 2 (Two-sample nonparametric testing):</strong> We observe two samples, <span class="math inline">\(X_1,\ldots,X_n \simiid P\)</span> and <span class="math inline">\(Y_1,\ldots,Y_m \simiid Q\)</span>, independently of each other. Without making any further assumptions about <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span>, we want to test the <em>nonparametric</em> hypotheses <span class="math inline">\(H_0:\; P = Q\)</span> vs <span class="math inline">\(H_1:\; P \neq Q\)</span>.</p>
<p>A hypothesis is called <em>simple</em> if it fully specifies the data distribution, and <em>composite</em> otherwise. In the examples above, the point null hypothesis <span class="math inline">\(H_0:\; \theta = \theta_0\)</span> is a simple hypothesis, and the other five are composite.</p>
<p>We’d like to use the data <span class="math inline">\(X\sim P_\theta\)</span> to determine which of <span class="math inline">\(H_0\)</span> or <span class="math inline">\(H_1\)</span> is true, but if a statistician has been called in then this is usually not possible through pure deductive reasoning. For example, if the distributions <span class="math inline">\(P_\theta\)</span> all have the same support, then any data set <span class="math inline">\(X\)</span> we see is logically consistent with any value of <span class="math inline">\(\theta\)</span> in the parameter space.</p>
<p>As usual, we have two options to get around this problem: we can beg the question (the Bayesian approach) or change the subject (the frequentist approach). The Bayesian answer to this problem is clean and simple: just calculate the posterior probabilities <span class="math inline">\(\Lambda(\Theta_0 \mid X) = \PP(\theta \in \Theta_0 \mid X)\)</span> and <span class="math inline">\(\Lambda(\Theta_1 \mid X) = \PP(\theta \in \Theta_1 \mid X)\)</span>.</p>
<p>But there are a variety of settings where this is regarded as unappealing: scientists, drug companies, and others often work very hard to design carefully controlled experiments where the only stochastic assumptions made are ones that very few people would disagree with, and we’d like to be able to analyze the data from those experiments without having to layer on any further assumptions.</p>
<p>The frequentist approach to this conundrum is to replace <em>inductive reasoning</em> with <em>inductive behavior</em>: we will come up with a decision rule to decide between the two hypotheses based on the data. Formally, we can say we will either</p>
<ol type="1">
<li><p>Reject <span class="math inline">\(H_0\)</span> (conclude that <span class="math inline">\(H_0\)</span> is implausible and <span class="math inline">\(H_1\)</span> must be true), or</p></li>
<li><p>Accept <span class="math inline">\(H_0\)</span> (go on believing <span class="math inline">\(H_0\)</span>).</p></li>
</ol>
<p>There is a basic asymmetry here in that <span class="math inline">\(H_0\)</span> is privileged as the default choice to be disconfirmed, or else corroborated. An analogy is often drawn to a criminal trial where the defendant is innocent until proven guilty.</p>
<p>In reality, of course, our credence in the null (or alternative) hypothesis should be continuous in the evidence that we observe; it would be ridiculous to flip from 100% belief in the null to 100% belief in the alternative just at the point where a normal random variable crosses some threshold. But there are real-world situations in which a dichotomous decision must be made. For example, should the FDA approve a drug, or not? Or, do we need to control for some variable in our experimental setup, or not? Still, it is helpful to retain some critical distance from the conceit that we are ever really dichotomously “rejecting” or “accepting” either hypothesis in an epistemic sense.</p>
<p>In many settings where hypothesis testing is applied, including the examples of two-sided <span class="math inline">\(Z\)</span>-testing and two-sample nonparametric testing above, there will always be points in the alternative hypothesis that explain the data even better than the null hypothesis does. As a result, even if we accept the conceit of making a dichotomous decision about what to “conclude,” it is implausible that we would ever “accept” <span class="math inline">\(H_0\)</span> in the sense of regarding <span class="math inline">\(H_1\)</span> as disconfirmed, even in an approximate sense. As a result, it is usually preferable to say that we “fail to reject <span class="math inline">\(H_0\)</span>” rather than saying we accept it. Though we will continue to use “accept” as a technical term in what follows, “fail to reject” has less risk of inadvertently misleading non-statisticians.</p>
</section>
<section id="the-critical-function" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="the-critical-function"><span class="header-section-number">2</span> The critical function</h2>
<p>We can describe a test by its <em>critical function</em> (a.k.a. <em>test function</em>):</p>
<p><span class="math display">\[
\phi(x) = \begin{cases}
0 &amp; \text{accept } H_0 \\
\gamma \in (0,1) &amp; \text{reject w.p. } \gamma \\
1 &amp; \text{reject } H_0
\end{cases}
\]</span></p>
<p>The option of randomizing our test by taking <span class="math inline">\(\phi(x) \in (0,1)\)</span> for some values <span class="math inline">\(x \in \cX\)</span> is helpful in theory, as we will see shortly, but it is hardly ever done in practice. A non-randomized test <span class="math inline">\(\phi\)</span> partitions <span class="math inline">\(\cX\)</span> into the <em>rejection region</em> <span class="math inline">\(R = \{x \in \cX: \phi(x) = 1\}\)</span> and the <em>acceptance region</em> <span class="math inline">\(A = \{x \in \cX:\; \phi(x) = 0\}\)</span>.</p>
<p>Most tests are defined by choosing a real-valued <em>test statistic</em> <span class="math inline">\(T(X)\)</span> and rejecting when <span class="math inline">\(T(X)\)</span> is above some <em>critical threshold</em> <span class="math inline">\(c \in \RR\)</span>. We say <span class="math inline">\(\phi\)</span> <em>rejects for large <span class="math inline">\(T(X)\)</span></em> if <span class="math display">\[
\phi(x) = \begin{cases}
0 &amp; T(x) &lt; c\\
\gamma \in (0,1) &amp; T(x) = c \text{ (if } \phi \text{ is randomized)} \\
1 &amp; T(x) &gt; c
\end{cases}
\]</span> Much of the art in designing a hypothesis test is in choosing a test statistic <span class="math inline">\(T(X)\)</span> that is as effective as possible at discriminating between <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span></p>
<section id="significance-level-and-power" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="significance-level-and-power"><span class="header-section-number">2.1</span> Significance level and power</h3>
<p>In carrying out a test, there are two types of errors that we can make: a <em>Type I error</em> (sometimes called a <em>false positive</em>) is when <span class="math inline">\(H_0\)</span> is true, but we reject it, and a <em>Type II error</em> (sometimes called a <em>false negative</em>) is when <span class="math inline">\(H_0\)</span> is false but we fail to reject it. One way to remember which is which is that the Type I error rate is of primary importance in deciding when to reject, and the Type II error rate is of secondary importance. Our usual goal, informally, is to make the probability of a Type II error under <span class="math inline">\(H_1\)</span> as small as we can, while controlling the Type I error rate below a prespecified value <span class="math inline">\(\alpha \in [0,1]\)</span>. Note that if <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span> are composite, we cannot necessarily speak of “the” Type I or Type II error rate, as it may depend on exactly which of the null or alternative parameter values we sample under.</p>
<p>The behavior of the test is fully summarized by the <em>power function</em> <span class="math inline">\(\beta(\theta) = \mathbb{E}_\theta[\phi(X)] = \PP_\theta(\text{Reject } H_0)\)</span>. In terms of this power function, our goal can be formally stated as <span class="math display">\[
\maxz_\phi \beta_\phi(\theta) \text{ for } \theta \in \Theta_1 \quad \text{ subject to } \beta_\phi(\theta) \leq \alpha \text{ for } \theta \in \Theta_0.
\]</span> We say <span class="math inline">\(\phi\)</span> is a <em>level-<span class="math inline">\(\alpha\)</span> test</em> if <span class="math inline">\(\sup_{\theta\in\Theta_0} \beta_\phi(\theta) \leq \alpha\)</span>. If this supremum is strictly below <span class="math inline">\(\alpha\)</span>, we say the test is <em>conservative</em>. A very common choice for <span class="math inline">\(\alpha\)</span> is <span class="math inline">\(0.05\)</span>; this began with a somewhat offhand remark by Ronald Fisher in his work when he introduced hypothesis testing, that he sometimes liked to use <span class="math inline">\(0.05\)</span> in his scientific work. It has become “the most influential offhand remark in the history of science,” according to Brad Efron at Stanford.</p>
<p>If <span class="math inline">\(H_0\)</span> is composite, this optimization problem has multiple constraints, and if <span class="math inline">\(H_1\)</span> is composite it has multiple objectives. A major question for the remainder of this lecture is whether we can find a test <span class="math inline">\(\phi^*\)</span> that optimizes all objectives at once.</p>
</section>
<section id="example-the-z-test" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="example-the-z-test"><span class="header-section-number">2.2</span> Example: the <span class="math inline">\(Z\)</span>-test</h3>
<p>A very common setting is that we observe some statistic <span class="math inline">\(Z(X) \sim N(\theta, 1)\)</span>, very often a summary statistic from a larger data set. If we are testing the one-sided hypothesis we might use the <em>right-tailed test</em> <span class="math inline">\(\phi_1(z) = 1\{z &gt; z_\alpha\}\)</span> that rejects for large values of <span class="math inline">\(Z\)</span>. Here <span class="math inline">\(z_\alpha = \Phi^{-1}(1-\alpha)\)</span> is the upper <span class="math inline">\(\alpha\)</span> quantile of the <span class="math inline">\(N(0,1)\)</span> distribution, and <span class="math inline">\(\Phi(z)\)</span> is the standard normal cdf.</p>
<p>If we want to test the two-sided hypothesis we might use the <em>two-tailed test</em> <span class="math inline">\(\phi_2(z) = 1\{|z| &gt; z_{\alpha/2}\}\)</span>. Now we are rejecting for large values of the test statistic <span class="math inline">\(|Z|\)</span>. The rejection regions for these tests at level <span class="math inline">\(\alpha = 0.1\)</span> are plotted below, along with the alternative distribution when <span class="math inline">\(\theta = 2.3\)</span>. The shaded blue region shows the power of the test under the alternative.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="hypothesis-testing_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The two tests’ power functions are plotted below for <span class="math inline">\(\alpha = 0.1\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="hypothesis-testing_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The power functions for both tests intersect the vertical axis <span class="math inline">\(\theta=0\)</span> at <span class="math inline">\(\alpha\)</span>, but the right-tailed test’s power function remains below <span class="math inline">\(\alpha\)</span> for all <span class="math inline">\(\theta &lt; 0\)</span> as well. Note that the right-tailed test is actually a valid test for the two-sided hypothesis, but we would be unlikely to want to use it since it has even less than <span class="math inline">\(\alpha\)</span> power to reject for negative values of <span class="math inline">\(\theta\)</span>. But this may give us a hint that it will not be possible to maximize power throughout the alternative, because the two-tailed test is in fact losing out to the right-tailed test when <span class="math inline">\(\theta &gt; 0\)</span>.</p>
<p>For the one-sided hypothesis testing problem, however, we might hold out hope that the right-tailed test is the best for all values in the alternative (all <span class="math inline">\(\theta &gt; 0\)</span>), and indeed it is.</p>
</section>
</section>
<section id="optimal-testing" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="optimal-testing"><span class="header-section-number">3</span> Optimal testing</h2>
<section id="likelihood-ratio-test" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="likelihood-ratio-test"><span class="header-section-number">3.1</span> Likelihood Ratio Test</h3>
<p><span class="math display">\[
\newcommand{\LR}{\textnormal{LR}}
\]</span></p>
<p>To begin thinking through optimality of a test, we will start with the simplest sort of hypothesis testing problem: a test of a simple null <span class="math inline">\(H_0:\; X\sim P_0\)</span> against a simple alternative <span class="math inline">\(H_1:\; X \sim P_1\)</span>. Without loss of generality, assume that <span class="math inline">\(P_0\)</span> and <span class="math inline">\(P_1\)</span> have densities <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p_1\)</span> with respect to a common dominating measure <span class="math inline">\(\mu\)</span> (such a measure always exists since we could take <span class="math inline">\(\mu = P_0 + P_1\)</span>).</p>
<p>The optimal level-<span class="math inline">\(\alpha\)</span> test in this setting is the one that rejects for large values of the <em>likelihood ratio statistic</em> <span class="math display">\[\LR(X) = \frac{p_1(X)}{p_0(X)}.\]</span> That is, our test will be of the form <span class="math display">\[
\phi(x) = \begin{cases}
1 &amp; \text{if } \LR(x) &gt; c \\
\gamma &amp; \text{if } \LR(x) = c \\
0 &amp; \text{if } \LR(x) &lt; c
\end{cases},
\]</span> where <span class="math inline">\(c &gt; 0\)</span> and <span class="math inline">\(\gamma \in (0,1)\)</span> are chosen to make <span class="math inline">\(\EE_0 \phi(X) = \alpha\)</span> exactly.</p>
<p>To gain intuiion for why this is the right test, recall that the power of a test with rejection region <span class="math inline">\(R\)</span> is <span class="math inline">\(\int_R p_1(x) \,d\mu(x)\)</span>, while the Type I error budget is <span class="math inline">\(\int_R p_0(x)\,d\mu(x)\)</span>. If the sample space were discrete, both integrals would just be sums over <span class="math inline">\(x \in R\)</span>, and we should construct a rejection region <span class="math inline">\(R\)</span> by collecting sample points for which we can buy us the most power <span class="math inline">\(p_1(x)\)</span> per unit of error budget <span class="math inline">\(p_0(x)\)</span> that we must spend. In short, <span class="math inline">\(p_1(x)\)</span> is the “bang” we get out of including <span class="math inline">\(x\)</span> in the rejection region, and <span class="math inline">\(p_0(x)\)</span> is the “buck” we must spend. The likelihood ratio statistic <span class="math inline">\(\LR(x)\)</span> is the ratio representing the “bang for our buck.”</p>
<p><strong>Theorem (Neyman–Pearson lemma):</strong> The likelihood ratio test <span class="math inline">\(\phi^*\)</span> with <span class="math inline">\(\EE_0 \phi(X) = \alpha\)</span> maximizes power among all level-<span class="math inline">\(\alpha\)</span> tests of <span class="math inline">\(H_0:\; X \sim P_0\)</span> vs <span class="math inline">\(H_1:\; X \sim P_1\)</span>.</p>
<p>For purposes of defining likelihood ratio tests, we use the convention that <span class="math inline">\(\LR(x) = \infty\)</span> if <span class="math inline">\(p_1(x) &gt; p_0(x) = 0\)</span> (including such points in the rejection region buys us additional power for free), and <span class="math inline">\(\LR(x)\)</span> is undefined if <span class="math inline">\(p_0(x)=p_1(x)=0\)</span> (since such points never come up under the null or the alternative).</p>
<p><strong>Proof:</strong> We are attempting to show <span class="math inline">\(\phi^*\)</span> solves the maximization problem <span class="math display">\[
\maxz \int \phi(x)p_1(x)\,d\mu(x) \quad \text{s.t. } \int \phi(x)p_0(x)\,d\mu(x) \leq \alpha.
\]</span></p>
<p>The Lagrange form is:</p>
<p><span class="math display">\[
\begin{aligned}
\mathcal{L}(\phi; \lambda)
&amp;= \int\phi(x) p_1(x)\,d\mu(x)  - \lambda\int \phi(x) p_0(x) \,d\mu(x) \\
&amp;= \int \phi(x) \left(p_1(x) - \lambda p_0(x)\right)\,d\mu(x)\\
&amp;= \int \phi(x) \left(\frac{p_1(x)}{p_0(x)} - \lambda\right)\,dP_0(x)\\
\end{aligned}
\]</span> If we want to maximize this expression over all functions <span class="math inline">\(\phi:\; \cX \to [0,1]\)</span>, it is clear we should take <span class="math inline">\(\phi(x)\)</span> as large as possible when <span class="math inline">\(\LR(x)-\lambda &gt; 0\)</span> (since the integrand is positive), and as small as possible when <span class="math inline">\(\LR(x) - \lambda &lt; 0\)</span> (since the integrand is negative). The best values are attained at the boundary points <span class="math inline">\(\{0,1\}\)</span>. Note it does not actually matter in this formulation what <span class="math inline">\(\phi(x)\)</span> is when <span class="math inline">\(\LR(x)=c\)</span>, so any test with <span class="math inline">\(\phi(x) = 1\)</span> when <span class="math inline">\(\LR(x) &gt; \lambda\)</span> and <span class="math inline">\(\phi(x) = 0\)</span> when <span class="math inline">\(\LR(x) &lt; \lambda\)</span> solves this Lagrange form. As a result we see that our proposed test <span class="math inline">\(\phi^*\)</span> maximizes the Lagrangian for <span class="math inline">\(c = \lambda\)</span>.</p>
<p>Next, consider any other test <span class="math inline">\(\phi(x)\)</span> with <span class="math inline">\(\EE_0\phi(X) \leq \alpha\)</span>. We have <span class="math display">\[
\begin{aligned}
\EE_1\phi(X) &amp;\leq \EE_1\phi(X) - c(\EE_0\phi(X) - \alpha)\\
&amp;\leq \EE_1\phi^*(X) - c(\EE_0 \phi^*(X) - \alpha)\\
&amp;= \EE_1\phi^*(x),
\end{aligned}
\]</span> where the first inequality comes from the assumption <span class="math inline">\(\EE_0\phi(X) \leq \alpha\)</span>, the second comes from the fact that <span class="math inline">\(\phi^*\)</span> maximizes the Lagrangian at <span class="math inline">\(\lambda = c\)</span>, and the last from our assumption <span class="math inline">\(\EE_0\phi(X) = \alpha\)</span>.</p>
<p>To ensure the condition <span class="math inline">\(\EE_0\phi(X) = \alpha\)</span>, we use threshold <span class="math inline">\(c_\alpha\)</span>, the upper-<span class="math inline">\(\alpha\)</span> quantile of the distribution of <span class="math inline">\(\LR(X)\)</span>. Where the randomization parameter <span class="math inline">\(\gamma\)</span> comes in is that the likelihood ratio statistic may be discrete, in which case we could have <span class="math display">\[
\PP_0 (\LR(X) &gt; c_\alpha) &lt; \alpha \leq \PP_0(\LR(X) \geq c_\alpha.
\]</span> In that case, we can “top off” our error budget at <span class="math inline">\(\alpha\)</span> by setting <span class="math display">\[
\gamma = \frac{\alpha - \PP_0(\LR(X) &gt; c)}{\PP_0(\LR(X) = c)}.
\]</span></p>
</section>
<section id="example-binomial" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="example-binomial"><span class="header-section-number">3.2</span> Example: Binomial</h3>
<p>To give a sense of how this works, suppose that we observe a binomial random variable measuring the same-side bias of some human coin flipper <span class="math display">\[
X \sim \text{Binom}(n,\theta) = \binom{n}{x}\theta^x(1-\theta)^{n-x}, \text{ for } x=0,1,\ldots,n.
\]</span> Inspired by the Diaconis, Holmes, and Montgomery paper, we want to test <span class="math inline">\(H_0:\; \theta = 0.5\)</span> vs <span class="math inline">\(H_1:\;\theta = 0.51\)</span>. The Neyman–Pearson lemma tells us to use the likelihood ratio: <span class="math display">\[
\LR(X) = \frac{p_{0.51}(X)}{p_{0.5}(X)} = \frac{0.51^X 0.49^{n-X}}{0.5^n} = \left(\frac{0.49}{0.5}\right)^n\left(\frac{0.51}{0.49}\right)^X
\]</span> We know that the most powerful test <span class="math inline">\(\phi^*(X)\)</span> rejects for large <span class="math inline">\(\LR(X)\)</span>, but because <span class="math inline">\(\LR(X)\)</span> is a strictly increasing function of <span class="math inline">\(X\)</span>, this is completely equivalent to rejecting for large <span class="math inline">\(X\)</span>. Thus, the optimal test will reject when <span class="math inline">\(X\)</span> is larger than its upper-<span class="math inline">\(\alpha\)</span> quantile <span class="math inline">\(c_\alpha\)</span> under sampling from the simple null <span class="math inline">\(P_{0.5}\)</span>.</p>
<p>If we choose some value like <span class="math inline">\(\alpha = 0.05\)</span> that is not divisible by <span class="math inline">\(2^{-n}\)</span>, there is no way we can hope to get a Type I error rate of exactly <span class="math inline">\(\alpha\)</span> under the null, because <span class="math inline">\(p_{0.5}(x) = \binom{n}{x}2^{-n}\)</span>. To fill our Type I error rate budget, we would then need to randomize at the rejection boundary.</p>
<p>For example, if <span class="math inline">\(n = 100\)</span> and <span class="math inline">\(\alpha = 0.05\)</span>, we will take <span class="math inline">\(c_\alpha = 58\)</span>, which is the <span class="math inline">\(0.95\)</span> quantile under the null. But <span class="math inline">\(\PP_{0.5}(X &gt; 58) = 0.044\)</span> instead of <span class="math inline">\(0.05\)</span>, which is the Type I error rate we asked for. As a result, we randomize at the boundary by setting <span class="math display">\[
\gamma = \frac{0.05-0.44}{\PP_{0.5}(X = 58)} = 0.26,
\]</span> so <span class="math inline">\(\phi^*\)</span> rejects with probability <span class="math inline">\(0.26\)</span> if <span class="math inline">\(X = 58\)</span>. The plot below shows the acceptance and rejection regions of the test on a probability mass function plot of the null distribution, with the bar at <span class="math inline">\(c_\alpha = 58\)</span> split according to the acceptance and rejection probabilities at the boundary.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="hypothesis-testing_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>In practice, we hardly ever use randomized tests. The conservative test <span class="math inline">\(\phi^*(X) = 1\{X &gt; 58\}\)</span> is also a likelihood ratio test, and indeed it is the most powerful test at its own level <span class="math inline">\(0.044\)</span>.</p>
<p>What if instead of the alternative <span class="math inline">\(H_1:\; \theta = 0.51\)</span>, we instead read the more recent empirical paper and decided <span class="math inline">\(H_1:\; \theta = 0.508\)</span> was better? Then, following the same steps as before, the likelihood ratio statistic would be <span class="math display">\[
\LR(X) = \left(\frac{0.492}{0.5}\right)^n \left(\frac{0.508}{0.492}\right)^X.
\]</span> Just as before, the likelihood ratio is increasing in <span class="math inline">\(X\)</span>, so the test rejects for large values of <span class="math inline">\(X\)</span>. And, just as before, we will set our threshold <span class="math inline">\((c,\gamma)\)</span> to control the Type I error at <span class="math inline">\(\alpha\)</span> under <span class="math inline">\(H_0:\; \theta = 0.5\)</span>. Notice that since we have the same test statistic and the same null, we are using exactly the same test. This would be true for any alternative value <span class="math inline">\(\theta_1 &gt; 0.5\)</span> (but if we used an alternative <span class="math inline">\(\theta_1 &lt; 0.5\)</span> we would reject for <em>small</em> <span class="math inline">\(X\)</span>). So we actually have in <span class="math inline">\(\phi^*\)</span> a test of the point null <span class="math inline">\(H_0:\theta = 0.5\)</span> against the <em>composite</em> alternative <span class="math inline">\(H_1:\; \theta &gt; 0.5\)</span>, which is simultaneously optimal over all alternative values. A test that achieves maximal power for all values <span class="math inline">\(\theta \in\Theta_1\)</span> is called <em>uniformly most powerful</em>.</p>
<p>Next we will turn this into a general condition for the same test to be optimal across the entire alternative.</p>
</section>
<section id="uniformly-most-powerful-tests" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="uniformly-most-powerful-tests"><span class="header-section-number">3.3</span> Uniformly most powerful tests</h3>
<p><strong>Definition:</strong> We say a test <span class="math inline">\(\phi^*\)</span> is a <em>uniformly most powerful</em> (UMP) level-<span class="math inline">\(\alpha\)</span> test of <span class="math inline">\(H_0\)</span> against <span class="math inline">\(H_1\)</span> if it is a valid level <span class="math inline">\(\alpha\)</span> test, and for any other valid test <span class="math inline">\(\phi\)</span>, we have <span class="math inline">\(\beta_{\phi^*}(\theta) \geq \beta_\phi(\theta)\)</span> for all <span class="math inline">\(\theta \in \Theta_1\)</span>.</p>
<p>In the binomial example above, the reason we found a UMP test is that the likelihood ratio statistic was increasing in <span class="math inline">\(X\)</span> no matter what alternative we chose, so the optimal thing to do was always to reject for large <span class="math inline">\(X\)</span>. We now generalize this condition:</p>
<p><strong>Definition:</strong> We say <span class="math inline">\(\cP = \{P_\theta:\; \theta \in \Theta \subseteq \RR\}\)</span> has <em>monotone likelihood ratios</em> (MLR) in the statistic <span class="math inline">\(T(X)\)</span> if <span class="math inline">\(p_{\theta_2}(x)/p_{\theta_1}(x)\)</span> is a non-decreasing function of <span class="math inline">\(T(x)\)</span>, for any pair of parameter values <span class="math inline">\(\theta_1 &lt; \theta_2\)</span>.</p>
<p>In a family with monotone likelihood ratios, one-tailed tests are UMP for one-sided testing problems:</p>
<p><strong>Theorem:</strong> Assume that <span class="math inline">\(\cP\)</span> has MLR in <span class="math inline">\(T(X)\)</span>, and consider testing <span class="math inline">\(H_0:\;\theta \leq \theta_0\)</span> against <span class="math inline">\(H_1:\; \theta &gt; \theta_0\)</span>, for some <span class="math inline">\(\theta_0 \in \Theta \subseteq \RR\)</span>. If <span class="math inline">\(\phi^*(X)\)</span> rejects for large <span class="math inline">\(T(X)\)</span>, then <span class="math inline">\(\phi^*\)</span> is UMP at level <span class="math inline">\(\alpha = \EE_{\theta_0}\phi^*(X)\)</span>.</p>
<p><strong>Proof:</strong> Consider any other level-<span class="math inline">\(\alpha\)</span> test <span class="math inline">\(\phi\)</span>, and any <span class="math inline">\(\theta_1 &gt; \theta_0\)</span>. We know that <span class="math inline">\(\phi\)</span> is also a valid level-<span class="math inline">\(\alpha\)</span> test of the simple null <span class="math inline">\(H_0:\; \theta=\theta_0\)</span> vs the simple alternative <span class="math inline">\(H_1:\; \theta=\theta_1\)</span>, and so is <span class="math inline">\(\phi^*(X)\)</span> by assumption. Because <span class="math inline">\(p_{\theta_1}(X)/p_{\theta_0}(X)\)</span> is a non-decreasing function of <span class="math inline">\(T(X)\)</span>, <span class="math inline">\(\phi^*(X)\)</span> is a likelihood ratio test for this problem, so we have <span class="math inline">\(\beta_{\phi^*}(\theta_1) \geq \beta_{\phi}(\theta_1)\)</span>.</p>
<p>Note further that <span class="math inline">\(\beta_{\phi^*}(\theta_1) \geq \alpha\)</span> for <span class="math inline">\(\theta_1&gt;\theta_0\)</span>, which we can see by comparing it to the test <span class="math inline">\(\phi(X) \equiv \alpha\)</span> that ignores the data.</p>
<p>It remains only to show that <span class="math inline">\(\phi^*\)</span> is a valid level-<span class="math inline">\(\alpha\)</span> test; we only assumed it controls Type I error at the boundary. Define <span class="math inline">\(\bar{\phi}(X) = 1-\phi^*(X)\)</span>, which rejects for <em>small</em> <span class="math inline">\(T(X)\)</span> (or equivalently for large values of <span class="math inline">\(-T(X)\)</span>). Note further that <span class="math inline">\(\bar{\phi}(X)\)</span> is a level-<span class="math inline">\((1-\alpha)\)</span> LRT of <span class="math inline">\(H_0:\;\theta = \theta_0\)</span> vs <span class="math inline">\(H_1:\; \theta = \theta_1\)</span>, for any <span class="math inline">\(\theta_1 &lt; \theta_0\)</span>. As a result, we can conclude that for <span class="math inline">\(\theta_1&lt;\theta_0\)</span>, we have <span class="math display">\[1-\alpha \leq \beta_{\bar{\phi}}(\theta_1) = 1-\beta_{\phi^*}(\theta_1),\]</span> completing the proof.</p>
<p>An important group of examples of MLR families is all one-parameter exponential families.</p>
<p><strong>Example (One-parameter exponential family):</strong> Consider a size-<span class="math inline">\(n\)</span> sample from the exponential family <span class="math display">\[
X_1,\ldots,X_n \simiid p_\eta(x) = e^{\eta T(x) - A(\eta)}h(x)
\]</span> Then, for any <span class="math inline">\(\eta_1 &lt;\eta_2\)</span>, the likelihood ratio for the full sample is <span class="math display">\[
\frac{\prod_i p_{\eta_2}(x_i)}{\prod_i p_{\eta_1}(x_i)} = \exp\left\{(\eta_2-\eta_1)\sum_i T(x_i) - n(A(\eta_2) - A(\eta_1))\right\},
\]</span> which is increasing in <span class="math inline">\(\sum_i T(x_i)\)</span> if <span class="math inline">\(\eta_2 &gt; \eta_1\)</span> (and otherwise it is decreasing in the same statistic). As a result, any likelihood ratio test will reject for large values of <span class="math inline">\(\sum_i T(X_i)\)</span>.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/stat210a\.berkeley\.edu\/fall-2025\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>